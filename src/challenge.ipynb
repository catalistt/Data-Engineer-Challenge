{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Latam Challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catalina Aliste Gonzalez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido/a a la resolucion del desafio Data Engineer Latam Challenge. El presente documento tiene como objetivo presentar el desarrollo de las funciones solicitadas y mostrar su funcionamiento. Tambien, se incluye el analisis del tiempo de ejecucion y memoria en uso de cada version de las funciones. Adicionalmente, se incorporan los supuestos elegidos y las instrucciones correspondientes para mejor entendimiento del lector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instalar los requisitos especificados en el archivo requirements.txt, para poder utilizar las bibliotecas asociadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1604.98s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memory-profiler==0.61.0\n",
      "  Using cached memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Collecting emoji==2.10.1\n",
      "  Using cached emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
      "Requirement already satisfied: psutil in /Users/catalina/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from memory-profiler==0.61.0->-r ../requirements.txt (line 1)) (5.9.8)\n",
      "Installing collected packages: memory-profiler, emoji\n",
      "Successfully installed emoji-2.10.1 memory-profiler-0.61.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definir una variable que contenga el path del archivo a evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Supuestos y consideraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los nombres de usuarios se obtuvieron desde el atributo 'username' contenido en el 'user' de cada tweet.\n",
    "- Se asume que la libreria \"emoji\" cuenta con todos los emojis actuales.\n",
    "- Para encontar los top 10 emojis más usados se utilizo el contenido ('content') del tweet. NO se consideraron emojis en \"quotedTweet\".\n",
    "- La cantidad de menciones (tags) se obtuvieron desde el contenido ('content') del tweet. NO se consideraron los tags en \"quotedTweet\".\n",
    "- Las menciones (tags) siguen el formato \"@...\", es decir, un arroba y luego texto seguido, hasta encontrar el primer espacio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Desarrollo de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta seccion, por cada funcion, se presentara primero la funcion desarrollada, luego el resultado de la funcion al procesar el archivo \"farmers-protest-tweets-2021-2-4.json\" y luego la explicacion mas detallada de la logica utilizada. Posteriormente, se exponen las diferencias sustanciales entre las funciones que realizan lo mismo pero con enfoques diferentes (por ejemplo, q1_time y q1_memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **q1_time**: Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desarrollo de q1_time (q1_time.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import create_json_array\n",
    "from collections import defaultdict\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "\n",
    "    # Obtener la lista de tweets del archivo\n",
    "    tweet_list = create_json_array.create_json_array(file_path)\n",
    "\n",
    "    # Inicializar diccionario para almacenar los recuentos de tweets por fecha y usuario\n",
    "    tweet_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Iterar los tweets y contar los tweets por fecha y usuario\n",
    "    for tweet in tweet_list:\n",
    "        # Obtener la fecha del tweet y el nombre de usuario\n",
    "        date_element = datetime.strptime(tweet['date'], '%Y-%m-%dT%H:%M:%S+00:00').date()\n",
    "        username_element = tweet['user']['username']\n",
    "\n",
    "        # Actualizar el recuento de tweets para esta fecha y usuario\n",
    "        tweet_counts[date_element][username_element] += 1\n",
    "\n",
    "    # Obtener las top 10 fechas con más tweets\n",
    "    sorted_dates = sorted(tweet_counts.items(), key=lambda x: sum(x[1].values()), reverse=True)[:10]\n",
    "\n",
    "    # Obtener el usuario con más publicaciones para cada una de las top 10 fechas, iterando sobre las fechas\n",
    "    top_10_result_list = []\n",
    "    for date, user_counts in sorted_dates:\n",
    "        top_user = max(user_counts, key=user_counts.get)\n",
    "        top_10_result_list.append((date, top_user))\n",
    "\n",
    "    return top_10_result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q1_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtención de la lista de tweets del archivo: Utiliza una función llamada create_json_array, proveniente del archivo create_json_array, para obtener la lista de tweets. Cabe mencionar que se separo esta funcion para poder utilizarla en otras funciones tambien y no repetir codigo constantemente.\n",
    "\n",
    "2. Inicialización del diccionario tweet_counts: Se inicializa un diccionario anidado utilizando defaultdict de Python. Este diccionario se utilizará para almacenar los recuentos de tweets por fecha y usuario. La estructura es: {fecha: {usuario: cantidad_de_tweets}}.\n",
    "\n",
    "3. Iteración a través de los tweets: Itera sobre cada tweet en la lista obtenida. Para cada tweet, extrae la fecha y el nombre de usuario.\n",
    "\n",
    "4. Actualización del recuento de tweets: Incrementa el recuento de tweets para la fecha y el usuario correspondientes en el diccionario tweet_counts.\n",
    "\n",
    "5. Obtención de las 10 fechas principales: Ordena el diccionario tweet_counts según la suma de los valores (es decir, la cantidad total de tweets para cada fecha) en orden descendente y selecciona las primeras 10 fechas.\n",
    "\n",
    "6. Obtención del usuario con más publicaciones para cada fecha seleccionada: Itera sobre las 10 fechas seleccionadas y para cada una encuentra el usuario con el mayor número de publicaciones.\n",
    "\n",
    "7. Construcción de la lista de resultados: Construye una lista de tuplas donde cada tupla contiene una fecha y el usuario que más publicaciones realizó en esa fecha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **q1_memory**: Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import create_json_array\n",
    "\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Obtener la lista de tweets del archivo\n",
    "    tweet_list = create_json_array.create_json_array(file_path)\n",
    "\n",
    "    # Inicializar un diccionario para almacenar los recuentos de tweets por fecha y usuario\n",
    "    tweet_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Inicializar un diccionario para almacenar el recuento de tweets por fecha\n",
    "    date_counts = defaultdict(int)\n",
    "\n",
    "    # Iterar los tweets y contar los tweets por fecha y usuario\n",
    "    for tweet in tweet_list:\n",
    "        # Obtener la fecha del tweet y el nombre de usuario\n",
    "        date_element = datetime.strptime(tweet['date'], '%Y-%m-%dT%H:%M:%S+00:00').date()\n",
    "        username_element = tweet['user']['username']\n",
    "\n",
    "        # Actualizar los recuentos de tweets para esta fecha y usuario\n",
    "        tweet_counts[date_element][username_element] += 1\n",
    "        date_counts[date_element] += 1\n",
    "\n",
    "    # Obtener las top 10 fechas con más tweets\n",
    "    sorted_dates = sorted(date_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    # Obtener el usuario con más publicaciones para cada una de las top 10 fechas\n",
    "    top_10_result_list = []\n",
    "    for date, _ in sorted_dates:\n",
    "        top_user = max(tweet_counts[date], key=tweet_counts[date].get)\n",
    "        top_10_result_list.append((date, top_user))\n",
    "\n",
    "    return top_10_result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtención de la lista de tweets del archivo: Utiliza una función llamada create_json_array, proveniente del archivo create_json_array, para obtener la lista de tweets\n",
    "\n",
    "2. Inicialización de los diccionarios: Se inicializan dos diccionarios utilizando defaultdict: tweet_counts para almacenar los recuentos de tweets por fecha y usuario, y date_counts para almacenar el recuento total de tweets por fecha.\n",
    "\n",
    "3. Iteración sobre los tweets y conteo de tweets: Se itera sobre cada tweet en la lista obtenida. Para cada tweet, se extrae la fecha y el nombre de usuario, y se actualizan los recuentos de tweets tanto en tweet_counts como en date_counts.\n",
    "\n",
    "4. Obtención de las top 10 fechas con más tweets: Se ordenan las fechas en el diccionario date_counts según el número total de tweets por fecha.\n",
    "\n",
    "5. Obtención del usuario con más publicaciones para cada fecha seleccionada: Para cada una de las top 10 fechas, se encuentra el usuario con el mayor número de publicaciones utilizando el diccionario tweet_counts, y se agrega una tupla de fecha y usuario a la lista top_10_result_list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diferencia entre q1_time y q1_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En q1_time, se cuentan todos los tweets primero y luego se procesan los resultados, lo que significa que todos los recuentos de tweets deben mantenerse en memoria antes de poder seleccionar las top 10 fechas y usuarios.\n",
    "\n",
    "En cambio, en q1_memory, tambien se cuentan todos los tweets primero, pero no se almacenan todos los recuentos de tweets en un diccionario completo antes de procesar los resultados. En lugar de eso, se calculan los recuentos de tweets directamente mientras se itera sobre los tweets, lo que puede reducir la cantidad de memoria necesaria para almacenar los recuentos en comparación con q1_time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **q2_time**: Los top 10 emojis más usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desarrollo de q2_time (q2_time.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import json\n",
    "from collections import Counter\n",
    "import emoji\n",
    "\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializar contador para contar emojis\n",
    "    emoji_counter = Counter()\n",
    "\n",
    "    # Abrir archivo e iterar sobre cada linea\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # Decodificar el JSON a un objeto Python\n",
    "                tweet = json.loads(line)\n",
    "                # Verificar si hay un campo 'content' en el tweet y almacenar\n",
    "                if 'content' in tweet:\n",
    "                    content = tweet['content']\n",
    "                    # Iterar sobre cada caracter del contenido del tweet y verificar si es emoji\n",
    "                    for char in content:\n",
    "                        if emoji.is_emoji(char):\n",
    "                            emoji_counter[char] += 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error al decodificar la línea:\", line)\n",
    "\n",
    "    # Obtener los top 10 emojis y sus recuentos\n",
    "    top_10_emojis = emoji_counter.most_common(10)\n",
    "    \n",
    "    return top_10_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q2_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 7286),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('✊', 2411),\n",
       " ('🌾', 2363),\n",
       " ('🏻', 2080),\n",
       " ('❤', 1779),\n",
       " ('🤣', 1668),\n",
       " ('🏽', 1218),\n",
       " ('👇', 1108)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inicializacion del contador de emojis: Se crea un contador (emoji_counter) utilizando la clase Counter. Este contador se utilizará para contar la frecuencia de cada emoji encontrado en los tweets.\n",
    "\n",
    "2. Lectura del archivo y procesamiento de cada linea: El archivo especificado por file_path se abre en modo de lectura ('r') y se itera sobre cada línea del archivo.\n",
    "\n",
    "3. Decodificación del JSON y conteo de emojis: Para cada linea del archivo, se intenta decodificar el JSON a un objeto Python utilizando json.loads(). Si la decodificación es exitosa y el tweet contiene un campo 'content', se obtiene el contenido del tweet y se itera sobre cada caracter para verificar si es un emoji utilizando la función emoji.is_emoji(). Si se encuentra un emoji, se incrementa el contador correspondiente en emoji_counter.\n",
    "\n",
    "4. Manejo de errores: Se manejan los errores de decodificacion JSON utilizando un bloque try-except, mostrando un mensaje de error en caso de que ocurra un error al decodificar una línea específica.\n",
    "\n",
    "5. Obtencion de los top 10 emojis y sus recuentos: se utiliza el método most_common(10) del contador emoji_counter para obtener los 10 emojis mas comunes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **q2_memory**: Los top 10 emojis más usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desarrollo de q2_memory (q2_memory.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import emoji\n",
    "import heapq\n",
    "import json\n",
    "\n",
    "\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializar contador para contar emojis\n",
    "    emoji_counts = {}\n",
    "\n",
    "    # Abrir archivo e iterar sobre cada linea\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # Decodificar el JSON a un objeto Python\n",
    "                tweet = json.loads(line)\n",
    "                # Verificar si hay un campo 'content' en el tweet\n",
    "                if 'content' in tweet:\n",
    "                    content = tweet['content']\n",
    "                    # Iterar sobre cada caracter del contenido del tweet y verificar si es emoji\n",
    "                    for char in content:\n",
    "                        if emoji.is_emoji(char):\n",
    "                            # Incrementar el recuento del emoji en el diccionario\n",
    "                            emoji_counts[char] = emoji_counts.get(char, 0) + 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error al decodificar la línea:\", line)\n",
    "\n",
    "    # Mantener solo los 10 emojis mas comunes utilizando un heap\n",
    "    top_10_emojis = []\n",
    "    for emoji_char, count in emoji_counts.items():\n",
    "        # Si el heap aun no tiene 10 elementos, simplemente agregamos el emoji\n",
    "        if len(top_10_emojis) < 10:\n",
    "            heapq.heappush(top_10_emojis, (count, emoji_char))\n",
    "\n",
    "        # Alternativamente, comparamos la cantidad del emoji actual con la del minimo en el heap\n",
    "        else:\n",
    "            # Usar la cuenta, descartar el emoji mientras\n",
    "            min_count, _ = top_10_emojis[0]\n",
    "\n",
    "            # Si la cantidad es mayor, eliminamos el emoji min y agregamos el emoji actual\n",
    "            if count > int(min_count):\n",
    "                heapq.heappop(top_10_emojis)\n",
    "                heapq.heappush(top_10_emojis, (count, emoji_char))\n",
    "\n",
    "    top_10_emojis.sort(reverse=True)\n",
    "\n",
    "    # Revertir el orden (cantidad, emoji) a (emoji, cantidad)\n",
    "    top_10_emojis = [(emoji_char, count) for count, emoji_char in top_10_emojis]\n",
    "\n",
    "\n",
    "    return top_10_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 7286),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('✊', 2411),\n",
       " ('🌾', 2363),\n",
       " ('🏻', 2080),\n",
       " ('❤', 1779),\n",
       " ('🤣', 1668),\n",
       " ('🏽', 1218),\n",
       " ('👇', 1108)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inicializacion del diccionario de recuentos de emojis: Se crea un diccionario (emoji_counts) para almacenar los recuentos de emojis encontrados en los tweets.\n",
    "\n",
    "2. Lectura del archivo y procesamiento de cada línea: Se abre el archivo especificado por file_path en modo de lectura y se itera sobre cada línea del archivo.\n",
    "\n",
    "3. Decodificacion del JSON y conteo de emojis: Para cada línea del archivo, se intenta decodificar el JSON a un objeto Python. Si la decodificación es exitosa y el tweet contiene un campo 'content', se obtiene el contenido del tweet y se itera sobre cada caracter para verificar si es un emoji. Si se encuentra un emoji, se incrementa el recuento correspondiente en el diccionario emoji_counts.\n",
    "\n",
    "4. Mantencion de los 10 emojis mas comunes utilizando un heap: Se utiliza una estructura de heap para mantener los 10 emojis mas comunes encontrados hasta el momento. Se mantienen los 10 emojis con los recuentos mas altos en el heap.\n",
    "\n",
    "5. Ordenamiento: Después de completar el proceso de conteo, los emojis y sus recuentos se ordenan en orden descendente según la cantidad de ocurrencias. Finalmente, se invierte el orden de cada tupla de (cantidad, emoji) a (emoji, cantidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diferencia entre q1_time y q1_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones estan hechas con diferentes estructuras de datos. q2_time utiliza un objeto Counter para contar los emojis encontrados en los tweets. Este objeto facilita el conteo de elementos en una colección, mientras que q2_memory utiliza un diccionario estandar (emoji_counts) para almacenar los recuentos de emojis. Esto requiere manejar manualmente la logica de conteo y mantenimiento de los recuentos.\n",
    "\n",
    "En q2_time se utiliza una estructura de datos mas conveniente pero potencialmente mas costosa en memoria (Counter), mientras que q2_memory optimiza el uso de memoria utilizando un enfoque mas manual basado en diccionario y un heap para mantener una lista de tamaño fijo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **q3_time**: El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desarrollo de q3_time (q3_time.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "import create_json_array \n",
    "import re\n",
    "\n",
    "\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "\n",
    "    # Inicializar contador para contar tags\n",
    "    user_counter = Counter()\n",
    "\n",
    "    # RE para encontrar tags de usuarios\n",
    "    re_tags = re.compile(r'@([^ ]+)')\n",
    "\n",
    "    # Obtener los tweets del archivo y contar tags de usuarios\n",
    "    tweet_list = create_json_array.create_json_array(file_path)\n",
    "    for tweet in tweet_list:\n",
    "        if 'content' in tweet:\n",
    "            # Encontrar todos los tags en el contenido del tweet\n",
    "            mentions = re_tags.findall(tweet['content'])\n",
    "            # Aumentar el recuento de cada usuario\n",
    "            user_counter.update(mentions)\n",
    "\n",
    "    # Obtener los top 10 usuarios mencionados\n",
    "    top_10_users = user_counter.most_common(10)\n",
    "    \n",
    "    return top_10_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q3_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inicializacion del contador de tags de usuarios: Se crea un objeto Counter llamado user_counter para contar las menciones de usuarios.\n",
    "\n",
    "2. RE para encontrar tags de usuarios: Se crea una expresión regular (re_tags) que busca patrones de tags de usuarios en los tweets. En este caso, busca cualquier secuencia de caracteres que comience con @ seguido de uno o mas caracteres, hasta que encuentra un espacio.\n",
    "\n",
    "3. Iteracion sobre los tweets y conteo de tags de usuarios: Se obtiene una lista de tweets del archivo utilizando la función auxiliar create_json_array. Luego, para cada tweet, se verifica si tiene un campo 'content'. Si lo tiene, se buscan todas las menciones de usuarios en el contenido del tweet, y se actualiza el contador user_counter con cada mencion encontrada.\n",
    "\n",
    "4. Obtencion de los top 10 usuarios mencionados: Se utiliza el metodo most_common(10) de Counter para obtener los 10 usuarios mas mencionados, junto con la cantidad de veces que fueron mencionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **q3_memory**: El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desarrollo de q3_memory (q3_memory.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "import create_json_array \n",
    "import re\n",
    "\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializar listas vacias para almacenar tweets y contador de tags\n",
    "    tweets_content = []\n",
    "    user_counter = []\n",
    "    flat_user_counter = []\n",
    "\n",
    "    # Obtener los tweets del archivo y guardar contenido\n",
    "    tweet_list = create_json_array.create_json_array(file_path)\n",
    "    for tweet in tweet_list:\n",
    "        tweets_content.append(tweet['content'])\n",
    "\n",
    "    # RE para encontrar tags de usuarios\n",
    "    re_tags = r'@[^ ]+'\n",
    "\n",
    "    # Encontrar tags de usuarios en el contenido de los tweets y almacenarlos en user_counter\n",
    "    for tweet in tweets_content:\n",
    "        mentions = re.findall(re_tags, tweet)\n",
    "        if mentions:\n",
    "            user_counter.append([mention[1:] for mention in mentions])\n",
    "\n",
    "    # Aplanar la lista de listas de tags de usuarios en una sola lista\n",
    "    for sublist in user_counter:\n",
    "        flat_user_counter.extend(sublist)\n",
    "\n",
    "    # Contar la frecuencia de cada tag de usuario\n",
    "    user_counter = Counter(flat_user_counter)\n",
    "\n",
    "    # Obtener los top 10 usuarios mencionados\n",
    "    top_10_users = user_counter.most_common(10)\n",
    "\n",
    "    return top_10_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inicializacion de estructuras de datos: Se inicializan listas para almacenar el contenido de los tweets (tweets_content), los tags de usuarios encontrados en cada tweet (user_counter), y una lista plana que contendrá todas las menciones de usuarios (flat_user_counter).\n",
    "\n",
    "2. Obtencion del contenido de los tweets: Se obtienen los tweets del archivo utilizando la función create_json_array y se guarda el contenido de cada tweet en la lista tweets_content.\n",
    "\n",
    "3. Busqueda de menciones de usuarios: Se utiliza una RE (re_tags) para encontrar tags de usuarios en el contenido de los tweets. Se itera sobre el contenido de cada tweet para encontrar todas las menciones y se almacenan en user_counter.\n",
    "\n",
    "4. Aplanamiento de la lista de menciones de usuarios: Se itera sobre la lista de listas user_counter para aplanarla en una sola lista (flat_user_counter), lo que facilita el conteo de las menciones de usuarios.\n",
    "\n",
    "5. Conteo de la frecuencia de cada usuario mencionado: Se utiliza el objeto Counter para contar la frecuencia de cada usuario mencionado en la lista plana flat_user_counter.\n",
    "\n",
    "6. Obtencion de los top 10 usuarios mencionados: Se utilizan el método most_common(10) del objeto Counter para obtener los 10 usuarios mas mencionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diferencia entre q3_time y q3_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En q3_time se simplifica el proceso de conteo utilizando estructuras de datos eficientes en el almacenamiento de los tweets, pero puede consumir mas memoria al cargarlos todos de una vez. En q3_memory, por otro lado, se utiliza un enfoque mas \"manual\" y es mas eficiente en cuanto a memoria al procesar los tweets de manera mas iterativa.\n",
    "\n",
    "Por otra parte, en cuanto al uso de RE, q3_time utiliza una expresion regular (re.compile(r'@([^ ]+)')) para encontrar los tags de usuarios en el contenido de los tweets. Esto proporciona una forma más rápida y eficiente de buscar y extraer los tags de usuarios, mientras que q3_memory utiliza una expresion regular (re.findall(re_tags, tweet)) para encontrar los tags de usuarios en cada tweet. Esto implica una operacion de busqueda mas simple pero puede ser menos eficiente en cuanto a rendimiento en comparacion con el uso de una expresion regular compilada.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit ('3.10.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44914d4c7007b17060e8f9668e1b46e9d3b685da379049d88caa7f623197c30c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
