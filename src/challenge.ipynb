{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Latam Challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catalina Aliste Gonzalez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido/a a la resolucion del desafio Data Engineer Latam Challenge. El presente documento tiene como objetivo presentar el desarrollo de las funciones solicitadas y mostrar su funcionamiento. Tambien, se incluye el analisis del tiempo de ejecucion y memoria en uso de cada version de las funciones. Adicionalmente, se incorporan los supuestos elegidos y las instrucciones correspondientes para mejor entendimiento del lector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instalar los requisitos especificados en el archivo requirements.txt, para poder utilizar las bibliotecas asociadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definir una variable que contenga el path del archivo a evaluar. <br>\n",
    "** Se debe agregar este archivo a la carpeta src. De esta manera, se podra definir la variable correctamente **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Supuestos y consideraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los nombres de usuarios se obtuvieron desde el atributo 'username' contenido en el 'user' de cada tweet.\n",
    "\n",
    "- Se asume que la libreria \"emoji\" cuenta con todos los emojis actuales.\n",
    "\n",
    "- Para encontar los top 10 emojis más usados se utilizo el contenido ('content') del tweet. NO se consideraron emojis en \"quotedTweet\".\n",
    "\n",
    "- La cantidad de menciones (tags) se obtuvieron desde el contenido ('content') del tweet. NO se consideraron los tags en \"quotedTweet\", ni tampoco se accedieron a las menciones directamente (\"mentionedUser\") para poder evaluar directamente el contenido del tweet.\n",
    "\n",
    "- Las menciones (tags) siguen el formato \"@...\", es decir, un arroba y luego texto seguido, hasta encontrar el primer espacio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Desarrollo de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta seccion, por cada funcion, se presentara primero la funcion desarrollada, luego el resultado de la funcion al procesar el archivo \"farmers-protest-tweets-2021-2-4.json\" y luego la explicacion mas detallada de la logica utilizada. Posteriormente, se exponen las diferencias sustanciales entre las funciones que realizan lo mismo pero con enfoques diferentes (por ejemplo, q1_time y q1_memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **q1_time**: Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desarrollo de q1_time (q1_time.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import create_json_array\n",
    "from collections import defaultdict\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "\n",
    "    # Obtener la lista de tweets del archivo\n",
    "    tweet_list = create_json_array.create_json_array(file_path)\n",
    "\n",
    "    # Inicializar diccionario para almacenar los recuentos de tweets por fecha y usuario\n",
    "    tweet_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Iterar los tweets y contar los tweets por fecha y usuario\n",
    "    for tweet in tweet_list:\n",
    "        # Obtener la fecha del tweet y el nombre de usuario\n",
    "        date_element = datetime.strptime(tweet['date'], '%Y-%m-%dT%H:%M:%S+00:00').date()\n",
    "        username_element = tweet['user']['username']\n",
    "\n",
    "        # Actualizar el recuento de tweets para esta fecha y usuario\n",
    "        tweet_counts[date_element][username_element] += 1\n",
    "\n",
    "    # Obtener las top 10 fechas con más tweets\n",
    "    sorted_dates = sorted(tweet_counts.items(), key=lambda x: sum(x[1].values()), reverse=True)[:10]\n",
    "\n",
    "    # Obtener el usuario con más publicaciones para cada una de las top 10 fechas, iterando sobre las fechas\n",
    "    top_10_result_list = []\n",
    "    for date, user_counts in sorted_dates:\n",
    "        top_user = max(user_counts, key=user_counts.get)\n",
    "        top_10_result_list.append((date, top_user))\n",
    "\n",
    "    return top_10_result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q1_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtención de la lista de tweets del archivo: Utiliza una función llamada create_json_array, proveniente del archivo create_json_array, para obtener la lista de tweets. Cabe mencionar que se separo esta funcion para poder utilizarla en otras funciones tambien y no repetir codigo constantemente.\n",
    "\n",
    "2. Inicialización del diccionario tweet_counts: Se inicializa un diccionario anidado utilizando defaultdict de Python. Este diccionario se utilizará para almacenar los recuentos de tweets por fecha y usuario. La estructura es: {fecha: {usuario: cantidad_de_tweets}}.\n",
    "\n",
    "3. Iteración a través de los tweets: Itera sobre cada tweet en la lista obtenida. Para cada tweet, extrae la fecha y el nombre de usuario.\n",
    "\n",
    "4. Actualización del recuento de tweets: Incrementa el recuento de tweets para la fecha y el usuario correspondientes en el diccionario tweet_counts.\n",
    "\n",
    "5. Obtención de las 10 fechas principales: Ordena el diccionario tweet_counts según la suma de los valores (es decir, la cantidad total de tweets para cada fecha) en orden descendente y selecciona las primeras 10 fechas.\n",
    "\n",
    "6. Obtención del usuario con más publicaciones para cada fecha seleccionada: Itera sobre las 10 fechas seleccionadas y para cada una encuentra el usuario con el mayor número de publicaciones.\n",
    "\n",
    "7. Construcción de la lista de resultados: Construye una lista de tuplas donde cada tupla contiene una fecha y el usuario que más publicaciones realizó en esa fecha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **q1_memory**: Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import create_json_array\n",
    "\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Obtener la lista de tweets del archivo\n",
    "    tweet_list = create_json_array.create_json_array(file_path)\n",
    "\n",
    "    # Inicializar un diccionario para almacenar los recuentos de tweets por fecha y usuario\n",
    "    tweet_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Inicializar un diccionario para almacenar el recuento de tweets por fecha\n",
    "    date_counts = defaultdict(int)\n",
    "\n",
    "    # Iterar los tweets y contar los tweets por fecha y usuario\n",
    "    for tweet in tweet_list:\n",
    "        # Obtener la fecha del tweet y el nombre de usuario\n",
    "        date_element = datetime.strptime(tweet['date'], '%Y-%m-%dT%H:%M:%S+00:00').date()\n",
    "        username_element = tweet['user']['username']\n",
    "\n",
    "        # Actualizar los recuentos de tweets para esta fecha y usuario\n",
    "        tweet_counts[date_element][username_element] += 1\n",
    "        date_counts[date_element] += 1\n",
    "\n",
    "    # Obtener las top 10 fechas con más tweets\n",
    "    sorted_dates = sorted(date_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    # Obtener el usuario con más publicaciones para cada una de las top 10 fechas\n",
    "    top_10_result_list = []\n",
    "    for date, _ in sorted_dates:\n",
    "        top_user = max(tweet_counts[date], key=tweet_counts[date].get)\n",
    "        top_10_result_list.append((date, top_user))\n",
    "\n",
    "    return top_10_result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtención de la lista de tweets del archivo: Utiliza una función llamada create_json_array, proveniente del archivo create_json_array, para obtener la lista de tweets\n",
    "\n",
    "2. Inicialización de los diccionarios: Se inicializan dos diccionarios utilizando defaultdict: tweet_counts para almacenar los recuentos de tweets por fecha y usuario, y date_counts para almacenar el recuento total de tweets por fecha.\n",
    "\n",
    "3. Iteración sobre los tweets y conteo de tweets: Se itera sobre cada tweet en la lista obtenida. Para cada tweet, se extrae la fecha y el nombre de usuario, y se actualizan los recuentos de tweets tanto en tweet_counts como en date_counts.\n",
    "\n",
    "4. Obtención de las top 10 fechas con más tweets: Se ordenan las fechas en el diccionario date_counts según el número total de tweets por fecha.\n",
    "\n",
    "5. Obtención del usuario con más publicaciones para cada fecha seleccionada: Para cada una de las top 10 fechas, se encuentra el usuario con el mayor número de publicaciones utilizando el diccionario tweet_counts, y se agrega una tupla de fecha y usuario a la lista top_10_result_list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diferencia entre q1_time y q1_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En q1_time, se cuentan todos los tweets primero y luego se procesan los resultados, lo que significa que todos los recuentos de tweets deben mantenerse en memoria antes de poder seleccionar las top 10 fechas y usuarios.\n",
    "\n",
    "En cambio, en q1_memory, tambien se cuentan todos los tweets primero, pero no se almacenan todos los recuentos de tweets en un diccionario completo antes de procesar los resultados. En lugar de eso, se calculan los recuentos de tweets directamente mientras se itera sobre los tweets, lo que puede reducir la cantidad de memoria necesaria para almacenar los recuentos en comparación con q1_time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **q2_time**: Los top 10 emojis más usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desarrollo de q2_time (q2_time.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import json\n",
    "from collections import Counter\n",
    "import emoji\n",
    "\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializar contador para contar emojis\n",
    "    emoji_counter = Counter()\n",
    "\n",
    "    # Abrir archivo e iterar sobre cada linea\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # Decodificar el JSON a un objeto Python\n",
    "                tweet = json.loads(line)\n",
    "                # Verificar si hay un campo 'content' en el tweet y almacenar\n",
    "                if 'content' in tweet:\n",
    "                    content = tweet['content']\n",
    "                    # Iterar sobre cada caracter del contenido del tweet y verificar si es emoji\n",
    "                    for char in content:\n",
    "                        if emoji.is_emoji(char):\n",
    "                            emoji_counter[char] += 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error al decodificar la línea:\", line)\n",
    "\n",
    "    # Obtener los top 10 emojis y sus recuentos\n",
    "    top_10_emojis = emoji_counter.most_common(10)\n",
    "    \n",
    "    return top_10_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q2_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 7286),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('✊', 2411),\n",
       " ('🌾', 2363),\n",
       " ('🏻', 2080),\n",
       " ('❤', 1779),\n",
       " ('🤣', 1668),\n",
       " ('🏽', 1218),\n",
       " ('👇', 1108)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inicializacion del contador de emojis: Se crea un contador (emoji_counter) utilizando la clase Counter. Este contador se utilizará para contar la frecuencia de cada emoji encontrado en los tweets.\n",
    "\n",
    "2. Lectura del archivo y procesamiento de cada linea: El archivo especificado por file_path se abre en modo de lectura ('r') y se itera sobre cada línea del archivo.\n",
    "\n",
    "3. Decodificación del JSON y conteo de emojis: Para cada linea del archivo, se intenta decodificar el JSON a un objeto Python utilizando json.loads(). Si la decodificación es exitosa y el tweet contiene un campo 'content', se obtiene el contenido del tweet y se itera sobre cada caracter para verificar si es un emoji utilizando la función emoji.is_emoji(). Si se encuentra un emoji, se incrementa el contador correspondiente en emoji_counter.\n",
    "\n",
    "4. Manejo de errores: Se manejan los errores de decodificacion JSON utilizando un bloque try-except, mostrando un mensaje de error en caso de que ocurra un error al decodificar una línea específica.\n",
    "\n",
    "5. Obtencion de los top 10 emojis y sus recuentos: se utiliza el método most_common(10) del contador emoji_counter para obtener los 10 emojis mas comunes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **q2_memory**: Los top 10 emojis más usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desarrollo de q2_memory (q2_memory.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import emoji\n",
    "import heapq\n",
    "import json\n",
    "\n",
    "\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializar contador para contar emojis\n",
    "    emoji_counts = {}\n",
    "\n",
    "    # Abrir archivo e iterar sobre cada linea\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # Decodificar el JSON a un objeto Python\n",
    "                tweet = json.loads(line)\n",
    "                # Verificar si hay un campo 'content' en el tweet\n",
    "                if 'content' in tweet:\n",
    "                    content = tweet['content']\n",
    "                    # Iterar sobre cada caracter del contenido del tweet y verificar si es emoji\n",
    "                    for char in content:\n",
    "                        if emoji.is_emoji(char):\n",
    "                            # Incrementar el recuento del emoji en el diccionario\n",
    "                            emoji_counts[char] = emoji_counts.get(char, 0) + 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error al decodificar la línea:\", line)\n",
    "\n",
    "    # Mantener solo los 10 emojis mas comunes utilizando un heap\n",
    "    top_10_emojis = []\n",
    "    for emoji_char, count in emoji_counts.items():\n",
    "        # Si el heap aun no tiene 10 elementos, simplemente agregamos el emoji\n",
    "        if len(top_10_emojis) < 10:\n",
    "            heapq.heappush(top_10_emojis, (count, emoji_char))\n",
    "\n",
    "        # Alternativamente, comparamos la cantidad del emoji actual con la del minimo en el heap\n",
    "        else:\n",
    "            # Usar la cuenta, descartar el emoji mientras\n",
    "            min_count, _ = top_10_emojis[0]\n",
    "\n",
    "            # Si la cantidad es mayor, eliminamos el emoji min y agregamos el emoji actual\n",
    "            if count > int(min_count):\n",
    "                heapq.heappop(top_10_emojis)\n",
    "                heapq.heappush(top_10_emojis, (count, emoji_char))\n",
    "\n",
    "    top_10_emojis.sort(reverse=True)\n",
    "\n",
    "    # Revertir el orden (cantidad, emoji) a (emoji, cantidad)\n",
    "    top_10_emojis = [(emoji_char, count) for count, emoji_char in top_10_emojis]\n",
    "\n",
    "\n",
    "    return top_10_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 7286),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('✊', 2411),\n",
       " ('🌾', 2363),\n",
       " ('🏻', 2080),\n",
       " ('❤', 1779),\n",
       " ('🤣', 1668),\n",
       " ('🏽', 1218),\n",
       " ('👇', 1108)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inicializacion del diccionario de recuentos de emojis: Se crea un diccionario (emoji_counts) para almacenar los recuentos de emojis encontrados en los tweets.\n",
    "\n",
    "2. Lectura del archivo y procesamiento de cada línea: Se abre el archivo especificado por file_path en modo de lectura y se itera sobre cada línea del archivo.\n",
    "\n",
    "3. Decodificacion del JSON y conteo de emojis: Para cada línea del archivo, se intenta decodificar el JSON a un objeto Python. Si la decodificación es exitosa y el tweet contiene un campo 'content', se obtiene el contenido del tweet y se itera sobre cada caracter para verificar si es un emoji. Si se encuentra un emoji, se incrementa el recuento correspondiente en el diccionario emoji_counts.\n",
    "\n",
    "4. Mantencion de los 10 emojis mas comunes utilizando un heap: Se utiliza una estructura de heap para mantener los 10 emojis mas comunes encontrados hasta el momento. Se mantienen los 10 emojis con los recuentos mas altos en el heap.\n",
    "\n",
    "5. Ordenamiento: Después de completar el proceso de conteo, los emojis y sus recuentos se ordenan en orden descendente según la cantidad de ocurrencias. Finalmente, se invierte el orden de cada tupla de (cantidad, emoji) a (emoji, cantidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diferencia entre q1_time y q1_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones estan hechas con diferentes estructuras de datos. q2_time utiliza un objeto Counter para contar los emojis encontrados en los tweets. Este objeto facilita el conteo de elementos en una colección, mientras que q2_memory utiliza un diccionario estandar (emoji_counts) para almacenar los recuentos de emojis. Esto requiere manejar manualmente la logica de conteo y mantenimiento de los recuentos.\n",
    "\n",
    "En q2_time se utiliza una estructura de datos mas conveniente pero potencialmente mas costosa en memoria (Counter), mientras que q2_memory optimiza el uso de memoria utilizando un enfoque mas manual basado en diccionario y un heap para mantener una lista de tamaño fijo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **q3_time**: El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desarrollo de q3_time (q3_time.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "import create_json_array \n",
    "import re\n",
    "\n",
    "\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "\n",
    "    # Inicializar contador para contar tags\n",
    "    user_counter = Counter()\n",
    "\n",
    "    # RE para encontrar tags de usuarios\n",
    "    re_tags = re.compile(r'@([^ ]+)')\n",
    "\n",
    "    # Obtener los tweets del archivo y contar tags de usuarios\n",
    "    tweet_list = create_json_array.create_json_array(file_path)\n",
    "    for tweet in tweet_list:\n",
    "        if 'content' in tweet:\n",
    "            # Encontrar todos los tags en el contenido del tweet\n",
    "            mentions = re_tags.findall(tweet['content'])\n",
    "            # Aumentar el recuento de cada usuario\n",
    "            user_counter.update(mentions)\n",
    "\n",
    "    # Obtener los top 10 usuarios mencionados\n",
    "    top_10_users = user_counter.most_common(10)\n",
    "    \n",
    "    return top_10_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q3_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2152),\n",
       " ('Kisanektamorcha', 1701),\n",
       " ('RakeshTikaitBKU', 1460),\n",
       " ('PMOIndia', 1335),\n",
       " ('RahulGandhi', 1058),\n",
       " ('RaviSinghKA', 984),\n",
       " ('GretaThunberg', 957),\n",
       " ('UNHumanRights', 900),\n",
       " ('rihanna', 880),\n",
       " ('meenaharris', 852)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inicializacion del contador de tags de usuarios: Se crea un objeto Counter llamado user_counter para contar las menciones de usuarios.\n",
    "\n",
    "2. RE para encontrar tags de usuarios: Se crea una expresión regular (re_tags) que busca patrones de tags de usuarios en los tweets. En este caso, busca cualquier secuencia de caracteres que comience con @ seguido de uno o mas caracteres, hasta que encuentra un espacio.\n",
    "\n",
    "3. Iteracion sobre los tweets y conteo de tags de usuarios: Se obtiene una lista de tweets del archivo utilizando la función auxiliar create_json_array. Luego, para cada tweet, se verifica si tiene un campo 'content'. Si lo tiene, se buscan todas las menciones de usuarios en el contenido del tweet, y se actualiza el contador user_counter con cada mencion encontrada.\n",
    "\n",
    "4. Obtencion de los top 10 usuarios mencionados: Se utiliza el metodo most_common(10) de Counter para obtener los 10 usuarios mas mencionados, junto con la cantidad de veces que fueron mencionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **q3_memory**: El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desarrollo de q3_memory (q3_memory.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "import create_json_array \n",
    "import re\n",
    "\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializar listas vacias para almacenar tweets y contador de tags\n",
    "    tweets_content = []\n",
    "    user_counter = []\n",
    "    flat_user_counter = []\n",
    "\n",
    "    # Obtener los tweets del archivo y guardar contenido\n",
    "    tweet_list = create_json_array.create_json_array(file_path)\n",
    "    for tweet in tweet_list:\n",
    "        tweets_content.append(tweet['content'])\n",
    "\n",
    "    # RE para encontrar tags de usuarios\n",
    "    re_tags = r'@[^ ]+'\n",
    "\n",
    "    # Encontrar tags de usuarios en el contenido de los tweets y almacenarlos en user_counter\n",
    "    for tweet in tweets_content:\n",
    "        mentions = re.findall(re_tags, tweet)\n",
    "        if mentions:\n",
    "            user_counter.append([mention[1:] for mention in mentions])\n",
    "\n",
    "    # Aplanar la lista de listas de tags de usuarios en una sola lista\n",
    "    for sublist in user_counter:\n",
    "        flat_user_counter.extend(sublist)\n",
    "\n",
    "    # Contar la frecuencia de cada tag de usuario\n",
    "    user_counter = Counter(flat_user_counter)\n",
    "\n",
    "    # Obtener los top 10 usuarios mencionados\n",
    "    top_10_users = user_counter.most_common(10)\n",
    "\n",
    "    return top_10_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultado de q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2152),\n",
       " ('Kisanektamorcha', 1701),\n",
       " ('RakeshTikaitBKU', 1460),\n",
       " ('PMOIndia', 1335),\n",
       " ('RahulGandhi', 1058),\n",
       " ('RaviSinghKA', 984),\n",
       " ('GretaThunberg', 957),\n",
       " ('UNHumanRights', 900),\n",
       " ('rihanna', 880),\n",
       " ('meenaharris', 852)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explicacion detallada de la logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inicializacion de estructuras de datos: Se inicializan listas para almacenar el contenido de los tweets (tweets_content), los tags de usuarios encontrados en cada tweet (user_counter), y una lista plana que contendrá todas las menciones de usuarios (flat_user_counter).\n",
    "\n",
    "2. Obtencion del contenido de los tweets: Se obtienen los tweets del archivo utilizando la función create_json_array y se guarda el contenido de cada tweet en la lista tweets_content.\n",
    "\n",
    "3. Busqueda de menciones de usuarios: Se utiliza una RE (re_tags) para encontrar tags de usuarios en el contenido de los tweets. Se itera sobre el contenido de cada tweet para encontrar todas las menciones y se almacenan en user_counter.\n",
    "\n",
    "4. Aplanamiento de la lista de menciones de usuarios: Se itera sobre la lista de listas user_counter para aplanarla en una sola lista (flat_user_counter), lo que facilita el conteo de las menciones de usuarios.\n",
    "\n",
    "5. Conteo de la frecuencia de cada usuario mencionado: Se utiliza el objeto Counter para contar la frecuencia de cada usuario mencionado en la lista plana flat_user_counter.\n",
    "\n",
    "6. Obtencion de los top 10 usuarios mencionados: Se utilizan el método most_common(10) del objeto Counter para obtener los 10 usuarios mas mencionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diferencia entre q3_time y q3_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En q3_time se simplifica el proceso de conteo utilizando estructuras de datos eficientes en el almacenamiento de los tweets, pero puede consumir mas memoria al cargarlos todos de una vez. En q3_memory, por otro lado, se utiliza un enfoque mas \"manual\" y es mas eficiente en cuanto a memoria al procesar los tweets de manera mas iterativa.\n",
    "\n",
    "Por otra parte, en cuanto al uso de RE, q3_time utiliza una expresion regular (re.compile(r'@([^ ]+)')) para encontrar los tags de usuarios en el contenido de los tweets. Esto proporciona una forma más rápida y eficiente de buscar y extraer los tags de usuarios, mientras que q3_memory utiliza una expresion regular (re.findall(re_tags, tweet)) para encontrar los tags de usuarios en cada tweet. Esto implica una operacion de busqueda mas simple pero puede ser menos eficiente en cuanto a rendimiento en comparacion con el uso de una expresion regular compilada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV. Evaluacion de la memoria en uso y tiempo de ejecucion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion, se presenta la medicion de memoria en uso y tiempo de ejecucion de las funciones desarrolladas. Al finalizar las mediciones, se presentan conclusiones y analisis con respecto a los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Memoria en uso: Para evaluar la memoria en uso, se utilizo memory-profiler (https://pypi.org/project/memory-profiler/), el cual genera archivos por cada evaluacion. A continuacion, se presenta el codigo para la generacion de los archivos con las medidas y, al final, una tabla resumen de estas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- q1_time vs q1_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17333.10s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mprof: Sampling memory every 0.1s\n",
      "running new process\n",
      "running as a Python program...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17340.14s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mprof: Sampling memory every 0.1s\n",
      "running new process\n",
      "running as a Python program...\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "!mprof run q1_time.py\n",
    "!mprof run q1_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- q2_time vs q2_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17346.92s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mprof: Sampling memory every 0.1s\n",
      "running new process\n",
      "running as a Python program...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17353.75s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mprof: Sampling memory every 0.1s\n",
      "running new process\n",
      "running as a Python program...\n"
     ]
    }
   ],
   "source": [
    "!mprof run q2_time.py\n",
    "!mprof run q2_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- q3_time vs q3_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17360.66s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mprof: Sampling memory every 0.1s\n",
      "running new process\n",
      "running as a Python program...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17367.41s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mprof: Sampling memory every 0.1s\n",
      "running new process\n",
      "running as a Python program...\n"
     ]
    }
   ],
   "source": [
    "!mprof run q3_time.py\n",
    "!mprof run q3_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tabla resumen de memoria en uso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Problema  | Memoria en uso, enfoque time | Memoria en uso, enfoque memory |\n",
    "| --------- | ---- | ---------- |\n",
    "| q1      | 1.631 MB  | 1.631 MB    |\n",
    "| q2    | 1.632 MB  | 1.632 MB |\n",
    "| q3  | 1.633 MB  | 1.633 MB  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tiempo de ejecucion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para medir el tiempo de ejecucion, se utilizaron Python Profilers (https://docs.python.org/3/library/profile.html). A continuacion, se presentan las estadisticas por funcion y, al final, una tabla resumen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- q1_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadisticas de tiempo de ejecucion q1_time\n",
      "         4377165 function calls in 10.568 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 2386281714.py:1(<module>)\n",
      "       13    0.000    0.000    0.000    0.000 3572717110.py:11(<lambda>)\n",
      "       13    0.000    0.000    0.000    0.000 3572717110.py:27(<lambda>)\n",
      "        1    0.247    0.247   10.568   10.568 3572717110.py:6(q1_time)\n",
      "   117407    0.234    0.000    6.141    0.000 __init__.py:299(loads)\n",
      "   117407    0.108    0.000    0.630    0.000 _strptime.py:26(_getlang)\n",
      "   117407    1.650    0.000    2.637    0.000 _strptime.py:309(_strptime)\n",
      "   117407    0.317    0.000    2.955    0.000 _strptime.py:565(_strptime_datetime)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "    49772    0.071    0.000    0.136    0.000 codecs.py:319(decode)\n",
      "        2    0.000    0.000    0.000    0.000 codeop.py:117(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 compilerop.py:180(extra_flags)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:102(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:130(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:139(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:279(helper)\n",
      "        1    0.896    0.896    7.190    7.190 create_json_array.py:5(create_json_array)\n",
      "   117407    0.374    0.000    5.848    0.000 decoder.py:332(decode)\n",
      "   117407    5.240    0.000    5.281    0.000 decoder.py:343(raw_decode)\n",
      "        1    0.000    0.000    0.000    0.000 genericpath.py:16(exists)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:1277(user_global_ns)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:3493(compare)\n",
      "        2    0.000    0.000   10.989    5.494 interactiveshell.py:3541(run_code)\n",
      "     3282    0.016    0.000    0.054    0.000 ipkernel.py:770(_clean_thread_parent_frames)\n",
      "     1641    0.009    0.000    0.013    0.000 ipkernel.py:785(<setcomp>)\n",
      "   117407    0.163    0.000    0.200    0.000 locale.py:396(normalize)\n",
      "   117407    0.127    0.000    0.327    0.000 locale.py:479(_parse_localename)\n",
      "   117407    0.143    0.000    0.523    0.000 locale.py:587(getlocale)\n",
      "     1641    0.006    0.000    0.013    0.000 pydevd_daemon_thread.py:103(<listcomp>)\n",
      "     1641    0.010    0.000    0.025    0.000 pydevd_daemon_thread.py:99(new_threading_enumerate)\n",
      "     8205    0.003    0.000    0.003    0.000 threading.py:1145(ident)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1737(cast)\n",
      "    49772    0.065    0.000    0.065    0.000 {built-in method _codecs.utf_8_decode}\n",
      "   117407    0.052    0.000    0.052    0.000 {built-in method _locale.setlocale}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        2    0.000    0.000   10.989    5.494 {built-in method builtins.exec}\n",
      "    19696    0.007    0.000    0.007    0.000 {built-in method builtins.getattr}\n",
      "   355503    0.041    0.000    0.041    0.000 {built-in method builtins.isinstance}\n",
      "   352221    0.045    0.000    0.045    0.000 {built-in method builtins.len}\n",
      "       10    0.005    0.001    0.005    0.001 {built-in method builtins.max}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        1    0.001    0.001    0.001    0.001 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "   117407    0.157    0.000    3.112    0.000 {built-in method strptime}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "     1641    0.001    0.000    0.001    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "   117407    0.021    0.000    0.021    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "   117417    0.014    0.000    0.014    0.000 {method 'append' of 'list' objects}\n",
      "   117407    0.013    0.000    0.013    0.000 {method 'date' of 'datetime.datetime' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   352221    0.047    0.000    0.047    0.000 {method 'end' of 're.Match' objects}\n",
      "   352221    0.048    0.000    0.048    0.000 {method 'get' of 'dict' objects}\n",
      "   117407    0.100    0.000    0.100    0.000 {method 'groupdict' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "   123971    0.016    0.000    0.016    0.000 {method 'keys' of 'dict' objects}\n",
      "   117407    0.018    0.000    0.018    0.000 {method 'lower' of 'str' objects}\n",
      "   352221    0.224    0.000    0.224    0.000 {method 'match' of 're.Pattern' objects}\n",
      "   117407    0.042    0.000    0.042    0.000 {method 'startswith' of 'str' objects}\n",
      "   234814    0.024    0.000    0.024    0.000 {method 'toordinal' of 'datetime.date' objects}\n",
      "     3282    0.001    0.000    0.001    0.000 {method 'values' of 'dict' objects}\n",
      "   117407    0.012    0.000    0.012    0.000 {method 'weekday' of 'datetime.date' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "profile = cProfile.Profile()\n",
    "profile.enable()\n",
    "q1_time(file_path)\n",
    "profile.disable()\n",
    "print(\"Estadisticas de tiempo de ejecucion q1_time\")\n",
    "profile.print_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- q1_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadisticas de tiempo de ejecucion q1_memory:\n",
      "         4377165 function calls in 10.667 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 4243694485.py:1(<module>)\n",
      "       13    0.000    0.000    0.000    0.000 545340298.py:11(<lambda>)\n",
      "       13    0.000    0.000    0.000    0.000 545340298.py:27(<lambda>)\n",
      "        1    0.239    0.239   10.667   10.667 545340298.py:6(q1_memory)\n",
      "   117407    0.223    0.000    6.345    0.000 __init__.py:299(loads)\n",
      "   117407    0.109    0.000    0.622    0.000 _strptime.py:26(_getlang)\n",
      "   117407    1.643    0.000    2.620    0.000 _strptime.py:309(_strptime)\n",
      "   117407    0.312    0.000    2.932    0.000 _strptime.py:565(_strptime_datetime)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "    49772    0.068    0.000    0.129    0.000 codecs.py:319(decode)\n",
      "        2    0.000    0.000    0.000    0.000 codeop.py:117(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 compilerop.py:180(extra_flags)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:102(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:130(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:139(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:279(helper)\n",
      "        1    0.836    0.836    7.326    7.326 create_json_array.py:5(create_json_array)\n",
      "   117407    1.284    0.000    6.067    0.000 decoder.py:332(decode)\n",
      "   117407    4.568    0.000    4.601    0.000 decoder.py:343(raw_decode)\n",
      "        1    0.000    0.000    0.000    0.000 genericpath.py:16(exists)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:1277(user_global_ns)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:3493(compare)\n",
      "        2    0.000    0.000   11.094    5.547 interactiveshell.py:3541(run_code)\n",
      "     3282    0.013    0.000    0.045    0.000 ipkernel.py:770(_clean_thread_parent_frames)\n",
      "     1641    0.008    0.000    0.011    0.000 ipkernel.py:785(<setcomp>)\n",
      "   117407    0.161    0.000    0.198    0.000 locale.py:396(normalize)\n",
      "   117407    0.126    0.000    0.324    0.000 locale.py:479(_parse_localename)\n",
      "   117407    0.139    0.000    0.513    0.000 locale.py:587(getlocale)\n",
      "     1641    0.006    0.000    0.010    0.000 pydevd_daemon_thread.py:103(<listcomp>)\n",
      "     1641    0.008    0.000    0.020    0.000 pydevd_daemon_thread.py:99(new_threading_enumerate)\n",
      "     8205    0.003    0.000    0.003    0.000 threading.py:1145(ident)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1737(cast)\n",
      "    49772    0.061    0.000    0.061    0.000 {built-in method _codecs.utf_8_decode}\n",
      "   117407    0.051    0.000    0.051    0.000 {built-in method _locale.setlocale}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        2    0.000    0.000   11.094    5.547 {built-in method builtins.exec}\n",
      "    19696    0.005    0.000    0.005    0.000 {built-in method builtins.getattr}\n",
      "   355503    0.040    0.000    0.040    0.000 {built-in method builtins.isinstance}\n",
      "   352221    0.044    0.000    0.044    0.000 {built-in method builtins.len}\n",
      "       10    0.005    0.001    0.005    0.001 {built-in method builtins.max}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        1    0.001    0.001    0.001    0.001 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "   117407    0.152    0.000    3.084    0.000 {built-in method strptime}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "     1641    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "   117407    0.021    0.000    0.021    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "   117417    0.013    0.000    0.013    0.000 {method 'append' of 'list' objects}\n",
      "   117407    0.013    0.000    0.013    0.000 {method 'date' of 'datetime.datetime' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   352221    0.045    0.000    0.045    0.000 {method 'end' of 're.Match' objects}\n",
      "   352221    0.048    0.000    0.048    0.000 {method 'get' of 'dict' objects}\n",
      "   117407    0.100    0.000    0.100    0.000 {method 'groupdict' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "   123971    0.016    0.000    0.016    0.000 {method 'keys' of 'dict' objects}\n",
      "   117407    0.018    0.000    0.018    0.000 {method 'lower' of 'str' objects}\n",
      "   352221    0.213    0.000    0.213    0.000 {method 'match' of 're.Pattern' objects}\n",
      "   117407    0.039    0.000    0.039    0.000 {method 'startswith' of 'str' objects}\n",
      "   234814    0.024    0.000    0.024    0.000 {method 'toordinal' of 'datetime.date' objects}\n",
      "     3282    0.001    0.000    0.001    0.000 {method 'values' of 'dict' objects}\n",
      "   117407    0.012    0.000    0.012    0.000 {method 'weekday' of 'datetime.date' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile = cProfile.Profile()\n",
    "profile.enable()\n",
    "q1_memory(file_path)\n",
    "profile.disable()\n",
    "print(\"Estadisticas de tiempo de ejecucion q1_memory:\")\n",
    "profile.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* q2_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadisticas de tiempo de ejecucion q2_time:\n",
      "         18308404 function calls in 19.854 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1   12.316   12.316   19.853   19.853 1308603378.py:6(q2_time)\n",
      "        1    0.000    0.000   19.853   19.853 1808460035.py:1(<module>)\n",
      "   117407    0.239    0.000    3.621    0.000 __init__.py:299(loads)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:565(__init__)\n",
      "      641    0.000    0.000    0.000    0.000 __init__.py:579(__missing__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:588(most_common)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:640(update)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "    49772    0.071    0.000    0.131    0.000 codecs.py:319(decode)\n",
      "        2    0.000    0.000    0.000    0.000 codeop.py:117(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 compilerop.py:180(extra_flags)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:102(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:130(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:139(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:279(helper)\n",
      " 17034083    3.785    0.000    3.785    0.000 core.py:316(is_emoji)\n",
      "   117407    0.296    0.000    3.324    0.000 decoder.py:332(decode)\n",
      "   117407    2.853    0.000    2.853    0.000 decoder.py:343(raw_decode)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:521(nlargest)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:563(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:577(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:1277(user_global_ns)\n",
      "        1    0.000    0.000    0.000    0.000 interactiveshell.py:315(_modified_open)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:3493(compare)\n",
      "        2    0.000    0.000   19.854    9.927 interactiveshell.py:3541(run_code)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1737(cast)\n",
      "    49772    0.060    0.000    0.060    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _heapq.heapify}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method _heapq.heapreplace}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        2    0.001    0.001   19.854    9.927 {built-in method builtins.exec}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "   117407    0.018    0.000    0.018    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "   117408    0.018    0.000    0.018    0.000 {built-in method builtins.len}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   234814    0.029    0.000    0.029    0.000 {method 'end' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "   234814    0.128    0.000    0.128    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "   117407    0.040    0.000    0.040    0.000 {method 'startswith' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile = cProfile.Profile()\n",
    "profile.enable()\n",
    "q2_time(file_path)\n",
    "profile.disable()\n",
    "print(\"Estadisticas de tiempo de ejecucion q2_time:\")\n",
    "profile.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* q2_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadisticas de tiempo de ejecucion q2_memory:\n",
      "         18354049 function calls in 19.495 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 1115872085.py:48(<listcomp>)\n",
      "        1   12.071   12.071   19.493   19.493 1115872085.py:7(q2_memory)\n",
      "        1    0.000    0.000    0.000    0.000 3561215337.py:1(<module>)\n",
      "   117407    0.233    0.000    3.561    0.000 __init__.py:299(loads)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "    49772    0.069    0.000    0.128    0.000 codecs.py:319(decode)\n",
      "        2    0.000    0.000    0.000    0.000 codeop.py:117(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 compilerop.py:180(extra_flags)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:102(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:130(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:139(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:279(helper)\n",
      " 17034083    3.725    0.000    3.725    0.000 core.py:316(is_emoji)\n",
      "   117407    0.285    0.000    3.272    0.000 decoder.py:332(decode)\n",
      "   117407    2.817    0.000    2.817    0.000 decoder.py:343(raw_decode)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:1277(user_global_ns)\n",
      "        1    0.000    0.000    0.000    0.000 interactiveshell.py:315(_modified_open)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:3493(compare)\n",
      "        2    0.000    0.000   19.495    9.747 interactiveshell.py:3541(run_code)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1737(cast)\n",
      "    49772    0.059    0.000    0.059    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method _heapq.heappop}\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method _heapq.heappush}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        2    0.001    0.001   19.495    9.747 {built-in method builtins.exec}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "   117407    0.017    0.000    0.017    0.000 {built-in method builtins.isinstance}\n",
      "   118048    0.018    0.000    0.018    0.000 {built-in method builtins.len}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   234814    0.029    0.000    0.029    0.000 {method 'end' of 're.Match' objects}\n",
      "    45636    0.008    0.000    0.008    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "   234814    0.124    0.000    0.124    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "   117407    0.039    0.000    0.039    0.000 {method 'startswith' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile = cProfile.Profile()\n",
    "profile.enable()\n",
    "q2_memory(file_path)\n",
    "profile.disable()\n",
    "print(\"Estadisticas de tiempo de ejecucion q2_memory:\")\n",
    "profile.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* q3_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadisticas de tiempo de ejecucion q3_time:\n",
      "         2146418 function calls in 8.372 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.174    0.174    7.926    7.926 3794401002.py:7(q3_time)\n",
      "        1    0.443    0.443    8.370    8.370 723810342.py:1(<module>)\n",
      "   117407    0.237    0.000    6.361    0.000 __init__.py:299(loads)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:565(__init__)\n",
      "        1    0.000    0.000    0.004    0.004 __init__.py:588(most_common)\n",
      "   117408    0.077    0.000    0.253    0.000 __init__.py:640(update)\n",
      "   117407    0.031    0.000    0.058    0.000 abc.py:117(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "    49772    0.073    0.000    0.138    0.000 codecs.py:319(decode)\n",
      "        2    0.000    0.000    0.000    0.000 codeop.py:117(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 compilerop.py:180(extra_flags)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:102(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:130(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:139(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:279(helper)\n",
      "        1    0.930    0.930    7.445    7.445 create_json_array.py:5(create_json_array)\n",
      "   117407    0.394    0.000    6.064    0.000 decoder.py:332(decode)\n",
      "   117407    5.431    0.000    5.472    0.000 decoder.py:343(raw_decode)\n",
      "        1    0.000    0.000    0.000    0.000 genericpath.py:16(exists)\n",
      "        1    0.004    0.004    0.004    0.004 heapq.py:521(nlargest)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:563(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:577(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:1277(user_global_ns)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:3493(compare)\n",
      "        2    0.000    0.000    8.372    4.186 interactiveshell.py:3541(run_code)\n",
      "     3282    0.016    0.000    0.056    0.000 ipkernel.py:770(_clean_thread_parent_frames)\n",
      "     1641    0.009    0.000    0.013    0.000 ipkernel.py:785(<setcomp>)\n",
      "     1641    0.006    0.000    0.013    0.000 pydevd_daemon_thread.py:103(<listcomp>)\n",
      "     1641    0.011    0.000    0.025    0.000 pydevd_daemon_thread.py:99(new_threading_enumerate)\n",
      "        1    0.000    0.000    0.000    0.000 re.py:249(compile)\n",
      "        1    0.000    0.000    0.000    0.000 re.py:288(_compile)\n",
      "     8205    0.004    0.000    0.004    0.000 threading.py:1145(ident)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1737(cast)\n",
      "   117407    0.027    0.000    0.027    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    49772    0.065    0.000    0.065    0.000 {built-in method _codecs.utf_8_decode}\n",
      "   117407    0.036    0.000    0.036    0.000 {built-in method _collections._count_elements}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _heapq.heapify}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method _heapq.heapreplace}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        2    0.002    0.001    8.372    4.186 {built-in method builtins.exec}\n",
      "    19696    0.007    0.000    0.007    0.000 {built-in method builtins.getattr}\n",
      "   238097    0.100    0.000    0.158    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "   117408    0.018    0.000    0.018    0.000 {built-in method builtins.len}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "     1641    0.001    0.000    0.001    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "   117407    0.014    0.000    0.014    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   234814    0.033    0.000    0.033    0.000 {method 'end' of 're.Match' objects}\n",
      "   117407    0.050    0.000    0.050    0.000 {method 'findall' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "     6564    0.001    0.000    0.001    0.000 {method 'keys' of 'dict' objects}\n",
      "   234814    0.134    0.000    0.134    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "   117407    0.042    0.000    0.042    0.000 {method 'startswith' of 'str' objects}\n",
      "     3282    0.001    0.000    0.001    0.000 {method 'values' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile = cProfile.Profile()\n",
    "profile.enable()\n",
    "q3_time(file_path)\n",
    "profile.disable()\n",
    "print(\"Estadisticas de tiempo de ejecucion q3_time:\")\n",
    "profile.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* q3_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadisticas de tiempo de ejecucion q2_memory:\n",
      "         18354049 function calls in 19.698 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 1115872085.py:48(<listcomp>)\n",
      "        1   12.143   12.143   19.698   19.698 1115872085.py:7(q2_memory)\n",
      "        1    0.000    0.000   19.698   19.698 3561215337.py:1(<module>)\n",
      "   117407    0.238    0.000    3.637    0.000 __init__.py:299(loads)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "    49772    0.070    0.000    0.130    0.000 codecs.py:319(decode)\n",
      "        2    0.000    0.000    0.000    0.000 codeop.py:117(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 compilerop.py:180(extra_flags)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:102(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:130(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:139(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:279(helper)\n",
      " 17034083    3.778    0.000    3.778    0.000 core.py:316(is_emoji)\n",
      "   117407    0.290    0.000    3.341    0.000 decoder.py:332(decode)\n",
      "   117407    2.876    0.000    2.876    0.000 decoder.py:343(raw_decode)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:1277(user_global_ns)\n",
      "        1    0.000    0.000    0.001    0.001 interactiveshell.py:315(_modified_open)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:3493(compare)\n",
      "        2    0.000    0.000   19.698    9.849 interactiveshell.py:3541(run_code)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1737(cast)\n",
      "    49772    0.060    0.000    0.060    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method _heapq.heappop}\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method _heapq.heappush}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        2    0.000    0.000   19.698    9.849 {built-in method builtins.exec}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "   117407    0.018    0.000    0.018    0.000 {built-in method builtins.isinstance}\n",
      "   118048    0.018    0.000    0.018    0.000 {built-in method builtins.len}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        1    0.001    0.001    0.001    0.001 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   234814    0.028    0.000    0.028    0.000 {method 'end' of 're.Match' objects}\n",
      "    45636    0.008    0.000    0.008    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "   234814    0.129    0.000    0.129    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "   117407    0.040    0.000    0.040    0.000 {method 'startswith' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile = cProfile.Profile()\n",
    "profile.enable()\n",
    "q2_memory(file_path)\n",
    "profile.disable()\n",
    "print(\"Estadisticas de tiempo de ejecucion q2_memory:\")\n",
    "profile.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tabla resumen de medidas de tiempo de ejecucion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Problema  | Tiempo de ejecucion enfoque time | Tiempo de ejecucion enfoque memory |\n",
    "| --------- | ---- | ---------- |\n",
    "| q1      | 10.568  | 10.667    |\n",
    "| q2    | 19.854  | 19.495  |\n",
    "| q3  | 8.372  | 19.698   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conclusiones de ambos analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con relacion al uso de memoria, se puede concluir que ambas versiones de las funciones tienen un comportamiento similar y apenas presentan variaciones entre si. Sin embargo, es importante destacar que estas conclusiones se basan en pruebas realizadas sin tener en cuenta el archivo de tweets. Dado que este archivo es de gran tamaño y contiene una gran cantidad de datos, es posible que tenga un impacto significativo en el uso de memoria, lo que podria modificar las comparaciones realizadas.\n",
    "\n",
    "En cuanto al analisis del tiempo de ejecucion, se observa que la función `q2_time` tarda más en ejecutarse que `q2_memory`, a pesar de lo esperado. Esta diferencia, aunque mínima, puede atribuirse al hecho de que, aunque `q2_time` es más eficiente en terminos de procesamiento interno, el manejo de grandes volúmenes de datos puede contrarrestar esta eficiencia y afectar el tiempo total de ejecucion, a pesar del enfoque inicial pensado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V. Oportunidades de mejora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion, se enlistan algunas de las oportunidades de mejora a las funciones implementadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Flexibilidad en el formato de fecha: Actualmente, la función asume que el formato de fecha en los tweets es especifico ('%Y-%m-%dT%H:%M:%S+00:00'). Podria hacerse mas flexible permitiendo que el formato de fecha sea configurable o detectado automaticamente.\n",
    "\n",
    "- Manejo de casos de \"empate\": Si hay varios usuarios con el mismo numero maximo de publicaciones en una fecha dada, la funcion actual solo devuelve uno de ellos. Podria modificarse para manejar casos de empate devolviendo todos los usuarios con el maximo numero de publicaciones que sean iguales.\n",
    "\n",
    "- Manejo de archivo grande: como el archivo de tweets es grande, podria ser util agregar algun tipo de mecanismo de lectura y procesamiento por lotes para evitar cargar todos los tweets en la memoria al mismo tiempo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit ('3.10.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44914d4c7007b17060e8f9668e1b46e9d3b685da379049d88caa7f623197c30c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
